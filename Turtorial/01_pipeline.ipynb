{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this turtorial we will learn about **pipeline()**. Easy way of using \"models\" for inference.  Pipelines are object abstract which offer a simple \"API\" dedicated to several tasks such as Sentiment Analysis, Masked Language Modeling, Feature Extraction, and so on. <br>\n",
    "\n",
    "*Pipelines* are made of: \n",
    "\n",
    "- A *tokenizer* in charge of mapping raw textual input to tokens.\n",
    "- A *model* to make predictions from the inputs.\n",
    "- Some (optional) post processing for enhancing model's output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/envs/vision/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-29 20:02:18.411440: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 20:02:18.655411: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-29 20:02:18.655469: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-29 20:02:18.697877: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-29 20:02:18.797447: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 20:02:18.799474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 20:02:20.283612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "##importing pipeline \n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Parameters of pipeline()\n",
    "we can call pipleline for different tasks as stated above. We can do so with \"task\" parameter. \n",
    "\n",
    "- task: define which pipeline will be returned. Some accepted \"task\" are:\n",
    "    - \"audio-classification\": will retrun a AudioClassificationPipeline\n",
    "    - \"text-classification\"\n",
    "    - \"image-classification\"\n",
    "    - \"image=feature-extraction\"\n",
    "    - \"document-question-answering\"\n",
    "    - \"fill-mask\"\n",
    "    - \"image-to-image\": Reutn ImagetoImagePipeline\n",
    "    - and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "### we can call pipleline for different tasks as stated above. We can do so with \"task\" parameter. \n",
    "\n",
    "sentiment_pipe=pipeline(task=\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  distilbert/distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    }
   ],
   "source": [
    "model_name=sentiment_pipe.model.config.name_or_path\n",
    "print('Model Name: ',model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipe.model ## this is the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9996511936187744}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now we can just feed the input for classification\n",
    "single_input=\"The movie sucks.\"\n",
    "sentiment_pipe(single_input)\n",
    "# print(f'Single Input O')\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998428821563721},\n",
       " {'label': 'NEGATIVE', 'score': 0.9998151659965515}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_inputs=[\"I like the movie.\",\"The movie was waste of time.\"] ## must be provided with list. \n",
    "sentiment_pipe(multiple_inputs) ## We will have list of results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter name: model, tokenizer, config\n",
    "\n",
    "- model (\"str\" or PreTrainedModel or TFPreTrainedModel, optional): The model will be used used by the pipeline to make predictions. We can provide \"srt\" or model_identifier or an actual instance of pretrainedModel.\n",
    "\n",
    "    Specify the name of the model to directly load model from the \"hub\".*** We can ignore \"task\" parameters if we are using this model_identifier('str') parameter.However, we should use \"task\" parameter if we are using pretrained_model. ****Also, if the name of the model is not provided then \"default\" model for the task will be used.*\n",
    "\n",
    "- Config(str or PretrainedConfig, optional): Configuration that will be used by the pipeline to call the model. This can be a model identifier (\"str\" parameters) or an actual pretrained model configuration inheriting from PretrainedConfig. \n",
    "    **if not provided**, the default configuration will be used. If model is provided, the default config for the model will be used. If the model will not be given then the default config for the given task will be used.\n",
    "\n",
    "- tokenizer(str or PreTrainedTokenizer, optional): Tokenizer will be used by the pipeline to encoder data for the model. This can be a model identifier (using, \"str\") or an actual pretrained tokenizer. \n",
    "\n",
    "    **if not provided**, the default tokenizer for the *given model* will be loaded(*if it is string*). If model is not given nor str is provided, then then default tokenizer for the config(*given*) is used. However, if *config* is also not given then the default \"tokenizer\" for the given task will be used. \n",
    "\n",
    "- feature_extractor(str or PreTrainedFeatureExtractor,*optional*)\": Feature extractor that will be used to encode data for the model. This can be a model identifier or actual pretrained feature extractor inheriting from *PreTrainedFeatureExtractor*.\n",
    "\n",
    "    **feature extractors are used for non-NLP models(Speech or Vision models).NLP model uses \"tokenizer\" to encode the data.**  Multimodels uses both \"tokenizer\" as well as \"feature_extractor\" to encode \"text\" and other modalities(vision, audio), respectively. \n",
    "\n",
    "    The selection of \"feature_extractor\" works similarly to that of \"tokenizer\" parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following, we will call a pipeline using \"identifier\" for the model, config parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID:distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "\n",
      "tokenizer_id:distilbert/distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    }
   ],
   "source": [
    "## retriving \"Identifier name of above sentiment_pipe\"\n",
    "model_id=sentiment_pipe.model.config.name_or_path\n",
    "## Could not find a way to retrive Config Name\n",
    "tokenizer_id=sentiment_pipe.tokenizer.name_or_path\n",
    "\n",
    "print(f'Model ID:{model_id}\\n\\ntokenizer_id:{tokenizer_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentiment_pipe=pipeline(model=model_id) ##model_id must be in \"hub\"\n",
    "\n",
    "\"\"\"\n",
    "Here, we only provided model parameters. Thus, tokenizer and config will be used by default for the given model.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Providing Config id\n",
    "sentiment_pipe=pipeline(model=model_id,\n",
    "tokenizer=tokenizer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipe.model ## Summarization of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998428821563721},\n",
       " {'label': 'NEGATIVE', 'score': 0.9998151659965515}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipe(multiple_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  distilbert/distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    }
   ],
   "source": [
    "### We can extract the name of the model \n",
    "model_name=sentiment_pipe.model.config.name_or_path\n",
    "print('Model Name: ',model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we provide model for \"text-classification\", and provide task \"audio-classification\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What if we use model_name as well as task; what if use for other task\n",
    "\n",
    "sentiment_pipe=pipeline(task='text-classification',model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'DistilBertForSequenceClassification' is not supported for audio-classification. Supported models are ['ASTForAudioClassification', 'Data2VecAudioForSequenceClassification', 'HubertForSequenceClassification', 'SEWForSequenceClassification', 'SEWDForSequenceClassification', 'UniSpeechForSequenceClassification', 'UniSpeechSatForSequenceClassification', 'Wav2Vec2ForSequenceClassification', 'Wav2Vec2BertForSequenceClassification', 'Wav2Vec2ConformerForSequenceClassification', 'WavLMForSequenceClassification', 'WhisperForAudioClassification'].\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipe=pipeline(task='audio-classification',model=model_name) ## We will see error model is not supported for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following, we will call a pipeline using \"PreTrainedModel\" (model), PreTrainedconfig (config), and PreTrainedTokenizer (tokenizers) parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in oder to import PreTrained (model, config, and tokenizer) we need to import few other modules\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification,AutoTokenizer\n",
    "\n",
    "## We are calling AutoModelForSequenceClassification sicne text_classification is a sequential classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID:distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "\n",
      "tokenizer_id:distilbert/distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    }
   ],
   "source": [
    "print(f'Model ID:{model_id}\\n\\ntokenizer_id:{tokenizer_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the model and tokenizer\n",
    "\n",
    "model_pretrained=AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "tokenizer_pretrained=AutoTokenizer.from_pretrained(pretrained_model_name_or_path=tokenizer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipe = pipeline(model=model_pretrained, tokenizer=tokenizer_pretrained, task=\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998428821563721},\n",
       " {'label': 'NEGATIVE', 'score': 0.9998151659965515}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipe(multiple_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### pipelines(): Other Parameters\n",
    "\n",
    "- num_workers(int,*optional*,default to 1): the numbers of workers to be used. (when the pipeline will use DataLoader, while passing a dataset on GPU for a pytorch model)\n",
    "\n",
    "- batch_size(int,*optional*,default to 1): Used for laoding dataset when using dataloader. For inference, this is not useful.  (in next turtorial **batching the Dataset.**)\n",
    "\n",
    "- \n",
    "\n",
    "  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipelines(): Other Parameters\n",
    "\n",
    "- framework (*str*,optional): Which framework to use. \"pt\" for PyTorch, or \"tf\" for Tensorflow. The specific framework must be installed. Default: \"pt\"\n",
    "\n",
    "- revision (str,*optional*, default to *main*): Determine which git version of task or model to be used. By default, *main* branch is used.\n",
    "\n",
    "- use_fast(bool, *optional*)\n",
    "\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
